{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6a6b4d-99b1-47ca-8cfd-a668539fdab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df2443f-50cc-49a9-9b4e-2f1018fc6904",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Parameters\n",
    "data_dir = \"data/vent\"  # specify data path\n",
    "classes = [\"free\", \"obstacle\", \"unknown\"]  # specify the image classes\n",
    "num_epochs = 30  # number of epochs to train\n",
    "model_name = \"model_cnn.pt\"  # saved model name\n",
    "trace_model_name = \"traced_model_cnn.pt\"  # saved traced model name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097ce74d-b561-4aa4-b899-8301205457a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "\n",
    "\n",
    "# Define transforms for the training data and testing data\n",
    "train_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize([256, 256]),\n",
    "        transforms.RandomRotation(30),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transforms = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Pass transforms in here, then run the next cell to see how the transforms look\n",
    "train_data = datasets.ImageFolder(data_dir + \"/train\", transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(data_dir + \"/test\", transform=test_transforms)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7534df6b-0f37-4bce-afa5-b34275ef314b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Visualize some of the data-----------------------\n",
    "# helper function to un-normalize and display an image\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    plt.imshow(np.transpose(img, (1, 2, 0)))  # convert from Tensor image\n",
    "\n",
    "\n",
    "# obtain one batch of training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()  # convert images to numpy for display\n",
    "# plot the images in the batch, along with the corresponding labels\n",
    "fig = plt.figure(figsize=(25, 4))\n",
    "# display 20 images\n",
    "for idx in np.arange(20):\n",
    "    ax = fig.add_subplot(2, 10, idx + 1, xticks=[], yticks=[])\n",
    "    imshow(images[idx])\n",
    "    ax.set_title(classes[labels[idx]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e83e333-f0c8-49c3-96bb-866b7619e3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use GPU if it's available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.densenet121(pretrained=True)\n",
    "\n",
    "# Freeze parameters so we don't backprop through them\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.classifier = nn.Sequential(\n",
    "    nn.Linear(1024, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.2),\n",
    "    nn.Linear(256, 3),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "\n",
    "# Only train the classifier parameters, feature parameters are frozen\n",
    "optimizer = optim.Adam(model.classifier.parameters(), lr=0.003)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afec4b9-6bbc-42ca-aae0-f9b2a6f3d42c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.to(device)\n",
    "\n",
    "epochs = num_epochs\n",
    "steps = 0\n",
    "running_loss = 0\n",
    "print_every = 5\n",
    "test_loss_min = np.Inf\n",
    "for epoch in range(epochs):\n",
    "    for inputs, labels in trainloader:\n",
    "        steps += 1\n",
    "        # Move input and label tensors to the default device\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logps = model.forward(inputs)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if steps % print_every == 0:\n",
    "            test_loss = 0\n",
    "            accuracy = 0\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in testloader:\n",
    "                    inputs, labels = inputs.to(device), labels.to(device)\n",
    "                    logps = model.forward(inputs)\n",
    "                    batch_loss = criterion(logps, labels)\n",
    "\n",
    "                    test_loss += batch_loss.item()\n",
    "\n",
    "                    # Calculate accuracy\n",
    "                    ps = torch.exp(logps)\n",
    "                    top_p, top_class = ps.topk(1, dim=1)\n",
    "                    equals = top_class == labels.view(*top_class.shape)\n",
    "                    accuracy += torch.mean(equals.type(torch.FloatTensor)).item()\n",
    "\n",
    "            print(\n",
    "                \"Epoch \",\n",
    "                epoch + 1,\n",
    "                \"/\",\n",
    "                epochs,\n",
    "                \".. \" \"Train loss: \",\n",
    "                running_loss / print_every,\n",
    "                \".. \" \"Test loss: \",\n",
    "                test_loss / len(testloader),\n",
    "                \".. \" \"Test accuracy: \",\n",
    "                accuracy / len(testloader),\n",
    "                \"\",\n",
    "            )\n",
    "            running_loss = 0\n",
    "\n",
    "            # save model if validation loss has decreased\n",
    "            if test_loss <= test_loss_min:\n",
    "                torch.save(model.state_dict(), model_name)\n",
    "                test_loss_min = test_loss\n",
    "\n",
    "                model.to(\"cpu\")\n",
    "                # An example input you would normally provide to your model's forward() method.\n",
    "                example = torch.rand(1, 3, 224, 224)\n",
    "                # Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "                traced_script_module = torch.jit.trace(model, example)\n",
    "                output = traced_script_module(torch.ones(1, 3, 224, 224))\n",
    "                print(output)\n",
    "                traced_script_module.save(trace_model_name)\n",
    "                model.to(device)\n",
    "\n",
    "            model.train()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
