<!-- HTML header for doxygen 1.9.0-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=9"/>
<meta name="generator" content="Doxygen 1.8.20"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>ISAAC: Acoustics camera</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<link rel="icon" href="favicon.png" type="image/png" />
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="resize.js"></script>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
<link href="freeflyer.css" rel="stylesheet" type="text/css"/>
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr style="height: 70px;">
  <td id="projectalign" style="padding-left: 0.5em;">
   <div id="projectname">ISAAC
   &#160;<span id="projectnumber">0.2.8</span>
   </div>
   <div id="projectbrief">Flight software for the ISAAC project, adding functionality to the Astrobee robot, operating inside the International Space Station.</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.8.20 -->
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
var searchBox = new SearchBox("searchBox", "search",false,'Search');
/* @license-end */
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(function() {
  initMenu('',true,false,'search.php','Search');
  $(document).ready(function() { init_search(); });
});
/* @license-end */</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
/* @license magnet:?xt=urn:btih:cf05388f2679ee054f2beb29a391d25f4e673ac3&amp;dn=gpl-2.0.txt GPL-v2 */
$(document).ready(function(){initNavTree('acoustics_camera.html',''); initResizable(); });
/* @license-end */
</script>
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

<div class="PageDoc"><div class="header">
  <div class="headertitle">
<div class="title">Acoustics camera </div>  </div>
</div><!--header-->
<div class="contents">
<div class="textblock"><h3><a class="anchor" id="autotoc_md72"></a>
Overview</h3>
<p>This camera simulates a microphone array, or, in other words, a directional microphone. Its readings are assembled into a spherical pattern, consisting of one floating-point measurement for each direction emerging from the microphone center. It is assumed that the microphone array is mounted on the robot and it takes readings as the robot moves around.</p>
<p>For visualization purposes, the microphone measurements are converted to an acoustic "image". Hence, a virtual camera is created centered at the microphone and with a certain pose that is ideally facing the direction where all or most of the interesting sounds are coming from. The reading at a pixel of that camera is the value of the microphone measurement in the direction of the ray going from the microphone (and camera) center through that pixel.</p>
<h3><a class="anchor" id="autotoc_md73"></a>
Installation</h3>
<p>The acoustics camera depends on the pyroomacoustics package. This package can be installed together with its dependencies in a Python 2.7 environment using the command: </p><pre class="fragment">pip install numpy==1.15.4 scipy==0.18 pillow==6 PyWavelets==0.4.0 \
  networkx==1.8 matplotlib==2.0.0 scikit-image==0.14              \
  pyroomacoustics==0.3.1
</pre><p>It would normally install itself in: </p><pre class="fragment">$HOME/.local/lib/python2.7/site-packages/pyroomacoustics
</pre><h3><a class="anchor" id="autotoc_md74"></a>
Running the acoustics camera</h3>
<p>The acoustics camera ROS node can be run as part of the simulator. For that, first set up the environment along the lines of: </p><pre class="fragment">export ASTROBEE_SOURCE_PATH=$HOME/astrobee/src
export ASTROBEE_BUILD_PATH=$HOME/astrobee
export ISAAC_WS=$HOME/isaac
source $ASTROBEE_BUILD_PATH/devel/setup.bash
source $ISAAC_WS/devel/setup.bash
</pre><p>then run: </p><pre class="fragment">roslaunch isaac sim.launch world:=iss rviz:=true acoustics_cam:=true \
  pose:="11.2 -7.72 5.0 0 0 0 0 1"
</pre><p>One must ensure that the "DEBUG: AcousticsCam" image checkbox is checked in RViz upon launch, to be able to visualize this image. If it is not checked, it should be checked manually, the current config should be saved from the RViz menu, and the simulation should be restarted.</p>
<p>It is also possible to start the simulator without this camera, and then launch this camera separately as: </p><pre class="fragment">source $ASTROBEE_BUILD_PATH/devel/setup.bash
source $ISAAC_WS/devel/setup.bash
roslaunch acoustics_cam acoustics_cam.launch output:=screen
</pre><p>The acoustics camera can be run without ROS as: </p><pre class="fragment">$ISAAC_WS/src/astrobee/simulation/acoustics_cam/nodes/acoustics_cam debug_mode
</pre><p>In that case it assumes that the robot pose is the value set in the field "debug_robot_pose" in acoustics_cam.json (see below). In this mode it will only create a plot of the acoustics cam image. The sources of sounds will be represented as crosses in this plot, and the camera (microphone) position will be shown as a star.</p>
<h3><a class="anchor" id="autotoc_md75"></a>
ROS communication</h3>
<p>The acoustics camera subscribes to </p><pre class="fragment">/loc/truth/pose
</pre><p>to get the robot pose. It publishes its image, camera pose, and camera intrinsics on topics: </p><pre class="fragment">/hw/cam_acoustics
/sim/acoustics_cam/pose
/sim/acoustics_cam/info
</pre><p>By default, the camera takes pictures as often as it can (see the configuration below), which is rarely, in fact, as it is slow. It listens however to the topic: </p><pre class="fragment">/comm/dds/command
</pre><p>for guest science commands that may tell it to take a single picture at a specific time, or to take pictures continuously. Such a command must use the app name "gov.nasa.arc.irg.astrobee.acoustics_cam_image" (which is the "s" field in the first command argument) for it to be processed.</p>
<h3><a class="anchor" id="autotoc_md76"></a>
Configuration</h3>
<p>The behavior of this camera is described in: </p><pre class="fragment"> $ISAAC_WS/src/astrobee/simulation/acoustics_cam/acoustics_cam.json
</pre><p>It has the following entries:</p>
<ul>
<li>room_corners: the min and max coordinates of the simulated room in which the directional microphone takes measurements. Since the room is assumed to be anechoic, so there is no reflection from room walls, the precise room dimensions are not important, as long as the room is big enough to contain the sources of sound and the possible positions of the microphone and the robot carrying it.</li>
<li>sound_sources: the locations of the sound sources, their strengths, and files having the specific sound patterns. Those can be used, together with a machine learning algorithm, to differentiate among different types of sound.</li>
<li>camera_to_body_transform: The transform from the camera to the robot body coordinate system.</li>
<li>distance_between_updates: How far the microphone/robot should move, in meters, before another reading can take place. Set this to 0 to remove this constraint.</li>
<li>continuous_picture_taking: If the camera should take pictures as often as it can (value is 1). The alternative is for it to wait until it receives a command over the guest science topic when a single picture should be taken (value is 0).</li>
<li>image_width, image_height, hfov: The camera image width, image height, and horizontal field of view (in radians).</li>
<li>intensity_range: The reconstructed sound intensity as measured by the acoustic camera will be clamped to this range and then scaled to the range of 0 to 255, and rounded to integer. The obtained grayscale image will be colorized and published.</li>
<li>debug_robot_pose: This is useful for testing this node without ROS. The translation and quaternion fields specified here correspond to what is published by the /loc/truth/pose topic. </li>
</ul>
</div></div><!-- contents -->
</div><!-- PageDoc -->
</div><!-- doc-content -->
<!-- HTML footer for doxygen 1.9.0-->
<!-- start footer part -->
</body>
</html>
